{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":234911,"sourceType":"datasetVersion","datasetId":99505}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ============================\n# IMPORTAR LIBRER√çAS NECESARIAS\n# ============================\n\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\nfrom tensorflow.keras.models import Model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:07:25.880957Z","iopub.execute_input":"2025-11-08T16:07:25.881322Z","iopub.status.idle":"2025-11-08T16:07:25.887963Z","shell.execute_reply.started":"2025-11-08T16:07:25.881295Z","shell.execute_reply":"2025-11-08T16:07:25.886628Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# ============================\n# DEFINIR RUTA DEL DATASET\n# ============================\n\npath = '/kaggle/input/face-expression-recognition-dataset/images/validation/'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:07:25.889503Z","iopub.execute_input":"2025-11-08T16:07:25.889813Z","iopub.status.idle":"2025-11-08T16:07:25.909456Z","shell.execute_reply.started":"2025-11-08T16:07:25.889789Z","shell.execute_reply":"2025-11-08T16:07:25.908075Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# ============================\n# LISTAR ARCHIVOS DE IM√ÅGENES\n# ============================\n\nimage_names = os.listdir(path)\nprint(f\"Total de im√°genes encontradas: {len(image_names)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:07:25.910653Z","iopub.execute_input":"2025-11-08T16:07:25.911002Z","iopub.status.idle":"2025-11-08T16:07:25.935851Z","shell.execute_reply.started":"2025-11-08T16:07:25.910976Z","shell.execute_reply":"2025-11-08T16:07:25.934751Z"}},"outputs":[{"name":"stdout","text":"Total de im√°genes encontradas: 7\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# ============================\n# CARGAR Y PREPROCESAR IM√ÅGENES\n# ============================\n\n# Lista para almacenar todas las im√°genes\nimages = []\nimage_paths = []\n\n# Recorrer cada subcarpeta ('angry', 'happy', 'surprise')\nfor folder in os.listdir(path):\n    folder_path = os.path.join(path, folder)\n    \n    if os.path.isdir(folder_path):\n        # Recorrer cada imagen dentro de la subcarpeta\n        for img_file in os.listdir(folder_path):\n            img_path = os.path.join(folder_path, img_file)\n            \n            # Cargar imagen solo si es un archivo\n            img = image.load_img(img_path, target_size=(224, 224))\n            img_array = image.img_to_array(img)\n            img_array = np.expand_dims(img_array, axis=0)\n            img_array = preprocess_input(img_array)\n            \n            images.append(img_array)\n            image_paths.append(img_path)  # Guardar tambi√©n el path de la imagen\n\n# Convertir la lista de im√°genes a array numpy\nimages = np.vstack(images)\n\nprint(f\"Total im√°genes cargadas: {len(images)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:07:25.938305Z","iopub.execute_input":"2025-11-08T16:07:25.938606Z","iopub.status.idle":"2025-11-08T16:07:59.532642Z","shell.execute_reply.started":"2025-11-08T16:07:25.938582Z","shell.execute_reply":"2025-11-08T16:07:59.531567Z"}},"outputs":[{"name":"stdout","text":"Total im√°genes cargadas: 7066\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# ============================\n# CARGAR MODELO VGG16\n# ============================\n\n# Modelo VGG16 preentrenado sin la capa de clasificaci√≥n final\nbase_model = VGG16(weights=None)\nmodel = Model(inputs=base_model.input, outputs=base_model.get_layer('fc1').output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:09:04.653063Z","iopub.execute_input":"2025-11-08T16:09:04.653402Z","iopub.status.idle":"2025-11-08T16:09:05.217624Z","shell.execute_reply.started":"2025-11-08T16:09:04.653379Z","shell.execute_reply":"2025-11-08T16:09:05.216467Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# ============================\n# EXTRAER VECTORES DE CARACTER√çSTICAS\n# ============================\n\nfeatures = model.predict(images, batch_size=32, verbose=1)\nprint(f\"Forma de los vectores de caracter√≠sticas: {features.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:09:09.539029Z","iopub.execute_input":"2025-11-08T16:09:09.539482Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m 33/221\u001b[0m \u001b[32m‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m28:28\u001b[0m 9s/step","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# ============================\n# REDUCCI√ìN DE DIMENSIONALIDAD\n# ============================\n\n# Aplicar PCA para reducir dimensiones a 50 componentes\npca = PCA(n_components=50)\nfeatures_pca = pca.fit_transform(features)\n\nprint(f\"Forma despu√©s de PCA: {features_pca.shape}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================\n# APLICAR CLUSTERING K-MEANS\n# ============================\n\n# Definir el n√∫mero de clusters\nn_clusters = 7\n\n# Crear y ajustar modelo de clustering\nkmeans = KMeans(n_clusters=n_clusters, random_state=42)\nclusters = kmeans.fit_predict(features_pca)\n\nprint(f\"Etiquetas de clustering asignadas: {np.unique(clusters)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================\n# EVALUAR CALIDAD DEL CLUSTERING\n# ============================\n\nsilhouette_avg = silhouette_score(features_pca, clusters)\nprint(f\"Coeficiente de silueta (Silhouette Score): {silhouette_avg:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================\n# VISUALIZAR EJEMPLOS DE CLUSTERS\n# ============================\n\ndef show_cluster_examples(cluster_label, n_examples=5):\n    \"\"\"\n    Muestra ejemplos de im√°genes de un cluster espec√≠fico.\n    \n    Args:\n    - cluster_label: N√∫mero de cluster que quieres visualizar.\n    - n_examples: Cantidad de im√°genes a mostrar.\n    \"\"\"\n    # Encontrar los √≠ndices de las im√°genes que pertenecen al cluster solicitado\n    indices = np.where(clusters == cluster_label)[0]\n    \n    plt.figure(figsize=(15, 3))\n    \n    for i, idx in enumerate(indices[:n_examples]):\n        img_path = image_paths[idx]  # üõ†Ô∏è CORREGIDO: usar la lista real de rutas\n        img = image.load_img(img_path, target_size=(224, 224))\n        \n        plt.subplot(1, n_examples, i + 1)\n        plt.imshow(img)\n        plt.axis('off')\n    \n    plt.suptitle(f\"Ejemplos del Cluster {cluster_label}\", fontsize=16)\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================\n# MOSTRAR EJEMPLOS DE CLUSTERS\n# ============================\n\n# Cambia el n√∫mero para ver otros clusters (0,1,2,...)\nshow_cluster_examples(cluster_label=1, n_examples=5)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}